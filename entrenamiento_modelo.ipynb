{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu5hrgW9ePbNT7XAEx205b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/100479095/Predictor_F1_2025/blob/main/entrenamiento_modelo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**INTRODUCCIÓN**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BBimslLGgbKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook se muestra el entrenamiento de varios modelos de IA para predecir las posiciones del último Gran Premio de Fórmula 1 de 2025, Abu Dabi. Para ello se realizó previamente un  preprocesado de los datos, recopilados de kaggle, lo cuáles se pueden encontrar en el fichero \"f1_trainning_data_2016_onwards.csv\". En este notebook se eliminarán algunas columnas de este csv con el objetivo de tener un dataset genérico y realizará una validación cruzada entre distintos modelos para encontrar el mejor, el cuál será utilizado para predecir los resultados finales del GP.\n"
      ],
      "metadata": {
        "id": "CR7bjM1WgsRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Carga de datos**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "uY57f9FwiNJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero que todo importamos las distintas librearís que estaremos utilizando a lo largo del entrenamiento y la validación cruzada."
      ],
      "metadata": {
        "id": "dhNNGU244hGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos las librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "LyxbvvDyiZIG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos los datos del **csv f1_training_data_2016_onwards.csv**, es importante recordar que este fichero es **generado por el script de carga de python** y para lograr que el código se ejecute de manera correcta hay que **subirlo a la plataforma de google colab**."
      ],
      "metadata": {
        "id": "OAUYY22B4pMT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8430d9c",
        "outputId": "ba25d5c8-fbb3-4204-df6f-cdf79f1ebc0f"
      },
      "source": [
        "df = pd.read_csv('f1_training_data_2016_onwards.csv')\n",
        "#mostramos las primeras 5 filas\n",
        "print(df.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   RACEID  DRIVERID  CONSTRUCTORID  CIRCUITID  ROUND  YEAR  LAP DISTANCE KM  \\\n",
            "0     948         1            131          1      1  2016            5.278   \n",
            "1     948         3            131          1      1  2016            5.278   \n",
            "2     948         4              1          1      1  2016            5.278   \n",
            "3     948         8              6          1      1  2016            5.278   \n",
            "4     948        13              3          1      1  2016            5.278   \n",
            "\n",
            "   LAPS RACE  AVG WIND SPEED  MAX WIND SPEED  ...  MATE LAST POSITION  \\\n",
            "0         57           17.35           25.97  ...                   1   \n",
            "1         57           17.35           25.97  ...                   2   \n",
            "2         57           17.35           25.97  ...                  12   \n",
            "3         57           17.35           25.97  ...                   4   \n",
            "4         57           17.35           25.97  ...                  13   \n",
            "\n",
            "   CONSTRUCTOR POINTS BEFORE GP  CONSTRUCTOR WINS SEASON       Q1       Q2  \\\n",
            "0                         703.0                        0  85351.0  84605.0   \n",
            "1                          43.0                        0  86934.0  84796.0   \n",
            "2                          27.0                        0  86537.0  86125.0   \n",
            "3                         428.0                        0  86579.0  85615.0   \n",
            "4                         257.0                        0  85918.0  85644.0   \n",
            "\n",
            "         Q3   BEST Q  GRID  SPRINT Y/N     MS RACE  \n",
            "0   83837.0  83837.0     1           0   6503625.0  \n",
            "1   84197.0  84197.0     2           0   6495565.0  \n",
            "2  300000.0  86125.0    11           0  10000000.0  \n",
            "3   85033.0  85033.0     4           0  10000000.0  \n",
            "4   85458.0  85458.0     6           0   6554544.0  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "347b3fb0"
      },
      "source": [
        "## Limpieza de ID\n",
        "\n",
        "En este apartadp eliminamos las columnas de RACEID y DRIVERID ya que son únicas o muy específicas y queremos que nuestro modelo sea capaz de generalizar entre los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd99b03a"
      },
      "source": [
        "#, 'CONSTRUCTORID', 'CIRCUITID', 'Q1', 'Q2', 'Q3'\n",
        "cols_to_drop = ['RACEID', 'DRIVERID', 'MS RACE']\n",
        "X = df.drop(columns=cols_to_drop)\n",
        "\n",
        "# Transformación Logarítmica del Target\n",
        "y = np.log1p(df['MS RACE'])\n",
        "\n",
        "# Identificar columnas\n",
        "categorical_features = ['CONSTRUCTORID', 'CIRCUITID']\n",
        "numerical_features = [col for col in X.columns if col not in categorical_features]\n",
        "\n",
        "# 3. Crear el Pipeline de Transformación\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        # Escalar numéricas para que el modelo no se sesgue por magnitudes grandes\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        # Convertir IDs a vectores binarios (One-Hot)\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d5ef0f7"
      },
      "source": [
        "## Definición y Evaluación de Modelos de Regresión\n",
        "\n",
        "---\n",
        "\n",
        "Para lograr la regresión vamos a seleccionar el mejor entre 3 modelos (Random Forest, MLP o GradientBoost)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8ffe2cc",
        "outputId": "c9a6abec-273e-489c-a8c5-b899682e5ecc"
      },
      "source": [
        "# Define models to evaluate\n",
        "models = [\n",
        "    ('RandomForestRegressor', RandomForestRegressor(n_estimators=50, random_state=42)),\n",
        "    ('MLPRegressor', MLPRegressor(max_iter=500, random_state=42)),\n",
        "    ('GradientBoostingRegressor', GradientBoostingRegressor(random_state=42))\n",
        "]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "# Perform stratified split by 'YEAR'\n",
        "print(\"Performing stratified train-test split by 'YEAR'...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=X['YEAR']\n",
        ")\n",
        "print(\"Distribution of 'YEAR' in X_train:\")\n",
        "print(X_train['YEAR'].value_counts(normalize=True).sort_index())\n",
        "\n",
        "print(\"\\nDistribution of 'YEAR' in X_test:\")\n",
        "print(X_test['YEAR'].value_counts(normalize=True).sort_index())\n",
        "\n",
        "# Initialize KFold for cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "print(\"KFold cross-validation object initialized.\")\n",
        "\n",
        "results = {}\n",
        "print(\"\\nEvaluating models with cross-validation (neg_mean_squared_error):\")\n",
        "# 4. Ejecutar Validación Cruzada\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "print(\"Comparando modelos (RMSE en escala Logarítmica - Menor es mejor):\")\n",
        "for name, model in models:\n",
        "    # Creamos un pipeline individual para cada modelo para evitar 'data leakage'\n",
        "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
        "\n",
        "    # cross_val_score devuelve 'neg_mean_squared_error', así que lo negamos y sacamos raíz\n",
        "    cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "    rmse_scores = np.sqrt(-cv_scores)\n",
        "\n",
        "    results.append(rmse_scores)\n",
        "    names.append(name)\n",
        "    print(f\"{name}: {rmse_scores.mean():.4f} (+/- {rmse_scores.std():.4f})\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing stratified train-test split by 'YEAR'...\n",
            "Distribution of 'YEAR' in X_train:\n",
            "YEAR\n",
            "2016    0.107558\n",
            "2017    0.093023\n",
            "2018    0.097674\n",
            "2019    0.097674\n",
            "2020    0.079070\n",
            "2021    0.102326\n",
            "2022    0.102326\n",
            "2023    0.102326\n",
            "2024    0.111337\n",
            "2025    0.106686\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Distribution of 'YEAR' in X_test:\n",
            "YEAR\n",
            "2016    0.106977\n",
            "2017    0.093023\n",
            "2018    0.097674\n",
            "2019    0.097674\n",
            "2020    0.079070\n",
            "2021    0.102326\n",
            "2022    0.102326\n",
            "2023    0.102326\n",
            "2024    0.111628\n",
            "2025    0.106977\n",
            "Name: proportion, dtype: float64\n",
            "KFold cross-validation object initialized.\n",
            "\n",
            "Evaluating models with cross-validation (neg_mean_squared_error):\n",
            "Comparando modelos (RMSE en escala Logarítmica - Menor es mejor):\n",
            "RandomForestRegressor: 0.3131 (+/- 0.1234)\n",
            "MLPRegressor: 1.0972 (+/- 0.4882)\n",
            "GradientBoostingRegressor: 0.3054 (+/- 0.1232)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f8eb67"
      },
      "source": [
        "## Optimización de Hiperparámetros\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64de3656",
        "outputId": "34b82e4d-7eaf-49ce-cdd5-d41b9b9854f6"
      },
      "source": [
        "print(\"Starting GridSearchCV for GradientBoostingRegressor...\")\n",
        "\n",
        "# Select the best model for hyperparameter tuning\n",
        "best_model_name = 'GradientBoostingRegressor'\n",
        "best_model = None\n",
        "for name, model in models:\n",
        "    if name == best_model_name:\n",
        "        best_model = model\n",
        "        break\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', best_model)])\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'model__n_estimators': [100, 200, 300],\n",
        "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
        "    'model__max_depth': [3, 4, 5]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    cv=kf,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit GridSearchCV to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"GridSearchCV completed.\")\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(f\"\\nBest parameters for {best_model_name}: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score (neg_mean_squared_error) for {best_model_name}: {grid_search.best_score_:.4f}\")\n",
        "print(f\"Best RMSE score for {best_model_name}: {np.sqrt(np.abs(grid_search.best_score_)):.4f}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting GridSearchCV for GradientBoostingRegressor...\n",
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
            "GridSearchCV completed.\n",
            "\n",
            "Best parameters for GradientBoostingRegressor: {'model__learning_rate': 0.1, 'model__max_depth': 4, 'model__n_estimators': 100}\n",
            "Best cross-validation score (neg_mean_squared_error) for GradientBoostingRegressor: -0.0445\n",
            "Best RMSE score for GradientBoostingRegressor: 0.2109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cdac9ad"
      },
      "source": [
        "## Entrenamiento del Modelo Final y Predicción\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ea5ead5",
        "outputId": "217ed019-5489-4ca4-c1ae-22fd9cefad92"
      },
      "source": [
        "print(\"Training final model with optimal hyperparameters and making predictions...\")\n",
        "\n",
        "# Get the best model from GridSearchCV\n",
        "best_model_final = grid_search.best_estimator_\n",
        "\n",
        "# 7. Predecir y devolver a la escala original (ms)\n",
        "y_pred_log = best_model_final.predict(X_test)\n",
        "y_pred = np.expm1(y_pred_log) # Inversa de log1p\n",
        "y_test = np.expm1(y_test)\n",
        "\n",
        "# 8. Evaluar\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "r2 = metrics.r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"RMSE (en ms): {rmse:,.0f}\")\n",
        "print(f\"MAPE (Error Porcentual): {mape:.2%}\")\n",
        "print(f\"R-squared (R2): {r2:.4f}\")\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training final model with optimal hyperparameters and making predictions...\n",
            "RMSE (en ms): 1,590,106\n",
            "MAPE (Error Porcentual): 14.34%\n",
            "R-squared (R2): 0.1980\n"
          ]
        }
      ]
    }
  ]
}