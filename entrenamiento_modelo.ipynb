{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu5z6ucnb4Z1XJHL2W1Y2a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/100479095/Predictor_F1_2025/blob/main/entrenamiento_modelo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**INTRODUCCIÓN**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BBimslLGgbKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook se muestra el entrenamiento de varios modelos de IA para predecir las posiciones del último Gran Premio de Fórmula 1 de 2025, Abu Dabi. Para ello se realizó previamente un  preprocesado de los datos, recopilados de kaggle, lo cuáles se pueden encontrar en el fichero \"f1_trainning_data_2016_onwards.csv\". En este notebook se eliminarán algunas columnas de este csv con el objetivo de tener un dataset genérico y realizará una validación cruzada entre distintos modelos para encontrar el mejor, el cuál será utilizado para predecir los resultados finales del GP.\n"
      ],
      "metadata": {
        "id": "CR7bjM1WgsRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Carga de datos**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "uY57f9FwiNJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero que todo importamos las distintas librearís que estaremos utilizando a lo largo del entrenamiento y la validación cruzada."
      ],
      "metadata": {
        "id": "dhNNGU244hGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos las librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "LyxbvvDyiZIG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos los datos del **csv f1_training_data_2016_onwards.csv**, es importante recordar que este fichero es **generado por el script de carga de python** y para lograr que el código se ejecute de manera correcta hay que **subirlo a la plataforma de google colab**."
      ],
      "metadata": {
        "id": "OAUYY22B4pMT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8430d9c",
        "outputId": "a8c21464-a55e-4f6f-cd76-395323bdb073"
      },
      "source": [
        "df = pd.read_csv('f1_training_data_2016_onwards.csv')\n",
        "#mostramos las primeras 5 filas\n",
        "print(df.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   RACEID  DRIVERID  CONSTRUCTORID  CIRCUITID  ROUND  YEAR  LAP DISTANCE KM  \\\n",
            "0     948         1            131          1      1  2016            5.278   \n",
            "1     948         3            131          1      1  2016            5.278   \n",
            "2     948         4              1          1      1  2016            5.278   \n",
            "3     948         8              6          1      1  2016            5.278   \n",
            "4     948        13              3          1      1  2016            5.278   \n",
            "\n",
            "   LAPS RACE  AVG WIND SPEED  MAX WIND SPEED  ...  MATE LAST POSITION  \\\n",
            "0         57           17.35           25.97  ...                   1   \n",
            "1         57           17.35           25.97  ...                   2   \n",
            "2         57           17.35           25.97  ...                  12   \n",
            "3         57           17.35           25.97  ...                   4   \n",
            "4         57           17.35           25.97  ...                  13   \n",
            "\n",
            "   CONSTRUCTOR POINTS BEFORE GP  CONSTRUCTOR WINS SEASON       Q1       Q2  \\\n",
            "0                         703.0                        0  85351.0  84605.0   \n",
            "1                          43.0                        0  86934.0  84796.0   \n",
            "2                          27.0                        0  86537.0  86125.0   \n",
            "3                         428.0                        0  86579.0  85615.0   \n",
            "4                         257.0                        0  85918.0  85644.0   \n",
            "\n",
            "         Q3   BEST Q  GRID  SPRINT Y/N     MS RACE  \n",
            "0   83837.0  83837.0     1           0   6503625.0  \n",
            "1   84197.0  84197.0     2           0   6495565.0  \n",
            "2  300000.0  86125.0    11           0  10000000.0  \n",
            "3   85033.0  85033.0     4           0  10000000.0  \n",
            "4   85458.0  85458.0     6           0   6554544.0  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "347b3fb0"
      },
      "source": [
        "## Limpieza de ID\n",
        "\n",
        "En este apartadp eliminamos las columnas de RACEID y DRIVERID ya que son únicas o muy específicas y queremos que nuestro modelo sea capaz de generalizar entre los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd99b03a"
      },
      "source": [
        "df_processed = df.drop(columns=['RACEID', 'DRIVERID'])\n",
        "#, 'CONSTRUCTORID', 'CIRCUITID'\n",
        "y = df_processed['MS RACE']\n",
        "X = df_processed.drop(columns=['MS RACE'])\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d5ef0f7"
      },
      "source": [
        "## Definición y Evaluación de Modelos de Regresión\n",
        "\n",
        "---\n",
        "\n",
        "Para lograr la regresión vamos a seleccionar el mejor entre 3 modelos (Random Forest, MLP o GradientBoost)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8ffe2cc",
        "outputId": "f2622301-27a5-4843-d628-3c064fdc66f0"
      },
      "source": [
        "# Define models to evaluate\n",
        "models = [\n",
        "    ('RandomForestRegressor', RandomForestRegressor(random_state=42)),\n",
        "    ('MLPRegressor', MLPRegressor(random_state=42, max_iter=1000, early_stopping=True)),\n",
        "    ('GradientBoostingRegressor', GradientBoostingRegressor(random_state=42))\n",
        "]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "# Perform stratified split by 'YEAR'\n",
        "print(\"Performing stratified train-test split by 'YEAR'...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=X['YEAR']\n",
        ")\n",
        "print(\"Distribution of 'YEAR' in X_train:\")\n",
        "print(X_train['YEAR'].value_counts(normalize=True).sort_index())\n",
        "\n",
        "print(\"\\nDistribution of 'YEAR' in X_test:\")\n",
        "print(X_test['YEAR'].value_counts(normalize=True).sort_index())\n",
        "\n",
        "# Initialize KFold for cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "print(\"KFold cross-validation object initialized.\")\n",
        "\n",
        "results = {}\n",
        "print(\"\\nEvaluating models with cross-validation (neg_mean_squared_error):\")\n",
        "for name, model in models:\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "    RMSE_scores = np.sqrt(np.abs(cv_scores))\n",
        "    mean_RMSE = RMSE_scores.mean()\n",
        "    results[name] = mean_RMSE\n",
        "\n",
        "print(\"\\nCross-validation results:\")\n",
        "for name, score in results.items():\n",
        "    print(f\"{name}: {score:.4f}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing stratified train-test split by 'YEAR'...\n",
            "Distribution of 'YEAR' in X_train_raw:\n",
            "YEAR\n",
            "2016    0.107558\n",
            "2017    0.093023\n",
            "2018    0.097674\n",
            "2019    0.097674\n",
            "2020    0.079070\n",
            "2021    0.102326\n",
            "2022    0.102326\n",
            "2023    0.102326\n",
            "2024    0.111337\n",
            "2025    0.106686\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Distribution of 'YEAR' in X_test_raw:\n",
            "YEAR\n",
            "2016    0.106977\n",
            "2017    0.093023\n",
            "2018    0.097674\n",
            "2019    0.097674\n",
            "2020    0.079070\n",
            "2021    0.102326\n",
            "2022    0.102326\n",
            "2023    0.102326\n",
            "2024    0.111628\n",
            "2025    0.106977\n",
            "Name: proportion, dtype: float64\n",
            "Stratified data split complete.\n",
            "X_train_raw shape: (3440, 30), y_train shape: (3440,)\n",
            "X_test_raw shape: (860, 30), y_test shape: (860,)\n",
            "KFold cross-validation object initialized.\n",
            "\n",
            "Evaluating models with cross-validation (neg_mean_squared_error):\n",
            "RandomForestRegressor: Mean MAE = 1592526.9461\n",
            "MLPRegressor: Mean MAE = 1936427.3389\n",
            "GradientBoostingRegressor: Mean MAE = 1588421.7270\n",
            "\n",
            "Cross-validation results:\n",
            "RandomForestRegressor: 1592526.9461\n",
            "MLPRegressor: 1936427.3389\n",
            "GradientBoostingRegressor: 1588421.7270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f8eb67"
      },
      "source": [
        "## Optimización de Hiperparámetros\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64de3656",
        "outputId": "a46f0233-d0ad-4717-df83-303a4846a42e"
      },
      "source": [
        "print(\"Starting GridSearchCV for GradientBoostingRegressor...\")\n",
        "\n",
        "# Select the best model for hyperparameter tuning\n",
        "best_model_name = 'GradientBoostingRegressor'\n",
        "best_model = None\n",
        "for name, model in models:\n",
        "    if name == best_model_name:\n",
        "        best_model = model\n",
        "        break\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 4, 5]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=best_model,\n",
        "    param_grid=param_grid,\n",
        "    cv=kf,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit GridSearchCV to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"GridSearchCV completed.\")\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(f\"\\nBest parameters for {best_model_name}: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score (neg_mean_squared_error) for {best_model_name}: {grid_search.best_score_:.4f}\")\n",
        "print(f\"Best RMSE score for {best_model_name}: {np.sqrt(np.abs(grid_search.best_score_)):.4f}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting GridSearchCV for GradientBoostingRegressor...\n",
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
            "GridSearchCV completed.\n",
            "\n",
            "Best parameters for GradientBoostingRegressor: {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 200}\n",
            "Best cross-validation score (neg_mean_squared_error) for GradientBoostingRegressor: -2492948499314.9468\n",
            "Best RMSE score for GradientBoostingRegressor: 1578907.3752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cdac9ad"
      },
      "source": [
        "## Entrenamiento del Modelo Final y Predicción\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ea5ead5",
        "outputId": "6846917c-17a0-431d-f896-a881beac5d3a"
      },
      "source": [
        "print(\"Training final model with optimal hyperparameters and making predictions...\")\n",
        "\n",
        "# Get the best model from GridSearchCV\n",
        "best_model_final = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_model_final.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
        "r2 = metrics.r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"\\nFinal Model Performance on Test Set:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R-squared (R2): {r2:.4f}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training final model with optimal hyperparameters and making predictions...\n",
            "\n",
            "Final Model Performance on Test Set:\n",
            "Mean Absolute Error (MAE): 1131551.5230\n",
            "Root Mean Squared Error (RMSE): 1597198.6233\n",
            "R-squared (R2): 0.1909\n"
          ]
        }
      ]
    }
  ]
}